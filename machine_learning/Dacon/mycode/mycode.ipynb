{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Seed 고정 함수\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42) # Seed 고정\n",
    "\n",
    "# CSV를 Parquet으로 변환하여 메모리 효율성 증대\n",
    "# def csv_to_parquet(csv_path, save_name):\n",
    "#     df = pd.read_csv(csv_path)\n",
    "#     df.to_parquet(f'./{save_name}.parquet')\n",
    "#     del df\n",
    "#     gc.collect()\n",
    "#     print(save_name, 'Done.')\n",
    "\n",
    "# 데이터 변환\n",
    "# csv_to_parquet('./train.csv', 'train')\n",
    "# csv_to_parquet('./test.csv', 'test')\n",
    "\n",
    "# 데이터 로드\n",
    "train = pd.read_parquet('./train.parquet')\n",
    "test = pd.read_parquet('./test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airline 복구 후 결측치 수:\n",
      "Train Airline 결측치: 11864\n",
      "Test Airline 결측치: 26893\n",
      "Airline Mapping Dictionary:\n",
      "WN      Southwest Airlines Co.\n",
      "UA                    Cape Air\n",
      "AA       Trans States Airlines\n",
      "DL    ExpressJet Airlines Inc.\n",
      "AS      Peninsula Airways Inc.\n",
      "B6             JetBlue Airways\n",
      "NK            Spirit Air Lines\n",
      "F9      Frontier Airlines Inc.\n",
      "HA        Empire Airlines Inc.\n",
      "G4               Allegiant Air\n",
      "VX              Virgin America\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리\n",
    "# Carrier_Code(IATA) → Airline 복구\n",
    "airline_mapping = train[['Carrier_Code(IATA)', 'Airline']].dropna().drop_duplicates().set_index('Carrier_Code(IATA)')['Airline'].to_dict()\n",
    "train['Airline'] = train['Carrier_Code(IATA)'].map(airline_mapping).fillna(train['Airline'])\n",
    "test['Airline'] = test['Carrier_Code(IATA)'].map(airline_mapping).fillna(test['Airline'])\n",
    "\n",
    "# 변환 결과 확인\n",
    "print(\"Airline 복구 후 결측치 수:\")\n",
    "print(\"Train Airline 결측치:\", train['Airline'].isna().sum())\n",
    "print(\"Test Airline 결측치:\", test['Airline'].isna().sum())\n",
    "\n",
    "print(\"Airline Mapping Dictionary:\")\n",
    "print(pd.Series(airline_mapping))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carrier_ID(DOT) 복구 후 결측치 수:\n",
      "Train Carrier_ID(DOT) 결측치: 1273\n",
      "Test Carrier_ID(DOT) 결측치: 2933\n",
      "Carrier Mapping Dictionary:\n",
      "                                           Carrier_ID(DOT)\n",
      "Airline                                                   \n",
      "Air Wisconsin Airlines Corp                        20046.0\n",
      "Alaska Airlines Inc.                               19930.0\n",
      "Allegiant Air                                      20368.0\n",
      "American Airlines Inc.                             19805.0\n",
      "Cape Air                                           20304.0\n",
      "Capital Cargo International                        20427.0\n",
      "Comair Inc.                                        20397.0\n",
      "Commutair Aka Champlain Enterprises, Inc.          20445.0\n",
      "Compass Airlines                                   21167.0\n",
      "Delta Air Lines Inc.                               19790.0\n",
      "Empire Airlines Inc.                               19690.0\n",
      "Endeavor Air Inc.                                  20363.0\n",
      "Envoy Air                                          20398.0\n",
      "ExpressJet Airlines Inc.                           19790.0\n",
      "Frontier Airlines Inc.                             20436.0\n",
      "GoJet Airlines, LLC d/b/a United Express           20500.0\n",
      "Hawaiian Airlines Inc.                             19690.0\n",
      "Horizon Air                                        19687.0\n",
      "JetBlue Airways                                    20409.0\n",
      "Mesa Airlines Inc.                                 20378.0\n",
      "Peninsula Airways Inc.                             19687.0\n",
      "Republic Airlines                                  20452.0\n",
      "SkyWest Airlines Inc.                              20304.0\n",
      "Southwest Airlines Co.                             19393.0\n",
      "Spirit Air Lines                                   20416.0\n",
      "Trans States Airlines                              19805.0\n",
      "United Air Lines Inc.                              19977.0\n",
      "Virgin America                                     21171.0\n"
     ]
    }
   ],
   "source": [
    "# Airline → Carrier_ID(DOT) 복구\n",
    "carrier_mapping = train[['Airline', 'Carrier_ID(DOT)']].dropna().drop_duplicates()\n",
    "carrier_mapping = carrier_mapping.groupby('Airline').first()  # Airline 기준으로 첫 번째 Carrier_ID(DOT)를 선택\n",
    "\n",
    "# Carrier_ID(DOT) 복구\n",
    "train['Carrier_ID(DOT)'] = train['Airline'].map(carrier_mapping['Carrier_ID(DOT)']).fillna(train['Carrier_ID(DOT)'])\n",
    "test['Carrier_ID(DOT)'] = test['Airline'].map(carrier_mapping['Carrier_ID(DOT)']).fillna(test['Carrier_ID(DOT)'])\n",
    "\n",
    "# 변환 결과 확인\n",
    "print(\"Carrier_ID(DOT) 복구 후 결측치 수:\")\n",
    "print(\"Train Carrier_ID(DOT) 결측치:\", train['Carrier_ID(DOT)'].isna().sum())\n",
    "print(\"Test Carrier_ID(DOT) 결측치:\", test['Carrier_ID(DOT)'].isna().sum())\n",
    "\n",
    "print(\"Carrier Mapping Dictionary:\")\n",
    "print(carrier_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means를 활용한 EDT/EAT 복구\n",
    "features_for_kmeans = ['Origin_Airport_ID', 'Destination_Airport_ID', 'Month', 'Day_of_Month', 'Distance']\n",
    "\n",
    "kmeans_data = train.dropna(subset=['Estimated_Departure_Time', 'Estimated_Arrival_Time'])[features_for_kmeans].copy()\n",
    "kmeans_target = train.dropna(subset=['Estimated_Departure_Time', 'Estimated_Arrival_Time']).copy()\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "kmeans.fit(kmeans_data)\n",
    "\n",
    "# 클러스터와 평균 비행 시간 계산\n",
    "kmeans_target['Cluster'] = kmeans.predict(kmeans_data)\n",
    "kmeans_target['Flight_Time'] = (\n",
    "    kmeans_target['Estimated_Arrival_Time'] - kmeans_target['Estimated_Departure_Time']\n",
    ") % 1440\n",
    "cluster_time_mapping = kmeans_target.groupby('Cluster')['Flight_Time'].mean().to_dict()\n",
    "\n",
    "# 복구 함수\n",
    "def recover_time(row, col):\n",
    "    if pd.isna(row['Estimated_Departure_Time']) or pd.isna(row['Estimated_Arrival_Time']):\n",
    "        cluster = kmeans.predict(pd.DataFrame([row[features_for_kmeans].values], columns=features_for_kmeans))[0]\n",
    "        avg_time = cluster_time_mapping.get(cluster, np.nan)\n",
    "        if col == 'Estimated_Departure_Time' and not pd.isna(row['Estimated_Arrival_Time']):\n",
    "            return (row['Estimated_Arrival_Time'] - avg_time) % 1440\n",
    "        elif col == 'Estimated_Arrival_Time' and not pd.isna(row['Estimated_Departure_Time']):\n",
    "            return (row['Estimated_Departure_Time'] + avg_time) % 1440\n",
    "    return row[col]\n",
    "\n",
    "# EDT와 EAT 복구\n",
    "for col in ['Estimated_Departure_Time', 'Estimated_Arrival_Time']:\n",
    "    train[col] = train.apply(lambda row: recover_time(row, col), axis=1)\n",
    "    test[col] = test.apply(lambda row: recover_time(row, col), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불필요한 특성 제거\n",
    "columns_to_drop = ['Cancelled', 'Diverted', 'Origin_Airport', 'Destination_Airport', 'Carrier_Code(IATA)', 'Airline', 'Origin_State', 'Destination_State']\n",
    "train = train.drop(columns=columns_to_drop, errors='ignore')\n",
    "test = test.drop(columns=columns_to_drop, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                    Non-Null Count    Dtype  \n",
      "---  ------                    --------------    -----  \n",
      " 0   ID                        1000000 non-null  object \n",
      " 1   Month                     1000000 non-null  int64  \n",
      " 2   Day_of_Month              1000000 non-null  int64  \n",
      " 3   Estimated_Departure_Time  988312 non-null   float64\n",
      " 4   Estimated_Arrival_Time    988312 non-null   float64\n",
      " 5   Origin_Airport_ID         1000000 non-null  int64  \n",
      " 6   Destination_Airport_ID    1000000 non-null  int64  \n",
      " 7   Distance                  1000000 non-null  float64\n",
      " 8   Carrier_ID(DOT)           998727 non-null   float64\n",
      " 9   Tail_Number               1000000 non-null  object \n",
      " 10  Delay                     255001 non-null   object \n",
      "dtypes: float64(4), int64(4), object(3)\n",
      "memory usage: 83.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 남은 결측치 처리\n",
    "numeric_cols = ['Estimated_Departure_Time', 'Estimated_Arrival_Time']\n",
    "train[numeric_cols] = train[numeric_cols].fillna(train[numeric_cols].mean())\n",
    "test[numeric_cols] = test[numeric_cols].fillna(test[numeric_cols].mean())\n",
    "\n",
    "train['Carrier_ID(DOT)'] = train['Carrier_ID(DOT)'].fillna(train['Carrier_ID(DOT)'].mode()[0])\n",
    "test['Carrier_ID(DOT)'] = test['Carrier_ID(DOT)'].fillna(train['Carrier_ID(DOT)'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                    Non-Null Count    Dtype  \n",
      "---  ------                    --------------    -----  \n",
      " 0   ID                        1000000 non-null  object \n",
      " 1   Month                     1000000 non-null  int64  \n",
      " 2   Day_of_Month              1000000 non-null  int64  \n",
      " 3   Estimated_Departure_Time  1000000 non-null  float64\n",
      " 4   Estimated_Arrival_Time    1000000 non-null  float64\n",
      " 5   Origin_Airport_ID         1000000 non-null  int64  \n",
      " 6   Destination_Airport_ID    1000000 non-null  int64  \n",
      " 7   Distance                  1000000 non-null  float64\n",
      " 8   Carrier_ID(DOT)           1000000 non-null  float64\n",
      " 9   Tail_Number               1000000 non-null  object \n",
      " 10  Delay                     255001 non-null   object \n",
      "dtypes: float64(4), int64(4), object(3)\n",
      "memory usage: 83.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6721048\ttotal: 221ms\tremaining: 1m 50s\n",
      "100:\tlearn: 0.4448594\ttotal: 18.3s\tremaining: 1m 12s\n",
      "200:\tlearn: 0.4414332\ttotal: 37.6s\tremaining: 55.9s\n",
      "300:\tlearn: 0.4393413\ttotal: 55.8s\tremaining: 36.9s\n",
      "400:\tlearn: 0.4376048\ttotal: 1m 15s\tremaining: 18.6s\n",
      "499:\tlearn: 0.4362768\ttotal: 1m 34s\tremaining: 0us\n",
      "\n",
      "Iteration 1\n",
      "High confidence pseudo-labels: 110049\n",
      "0:\tlearn: 0.6641374\ttotal: 319ms\tremaining: 2m 39s\n",
      "100:\tlearn: 0.3277006\ttotal: 27.5s\tremaining: 1m 48s\n",
      "200:\tlearn: 0.3232787\ttotal: 54.4s\tremaining: 1m 20s\n",
      "300:\tlearn: 0.3211132\ttotal: 1m 21s\tremaining: 53.8s\n",
      "400:\tlearn: 0.3197303\ttotal: 1m 49s\tremaining: 26.9s\n",
      "499:\tlearn: 0.3187380\ttotal: 2m 16s\tremaining: 0us\n",
      "\n",
      "Iteration 2\n",
      "High confidence pseudo-labels: 218205\n",
      "0:\tlearn: 0.6599741\ttotal: 356ms\tremaining: 2m 57s\n",
      "100:\tlearn: 0.2677816\ttotal: 36.2s\tremaining: 2m 22s\n",
      "200:\tlearn: 0.2638941\ttotal: 1m 11s\tremaining: 1m 46s\n",
      "300:\tlearn: 0.2620727\ttotal: 1m 47s\tremaining: 1m 10s\n",
      "400:\tlearn: 0.2609973\ttotal: 2m 22s\tremaining: 35.3s\n",
      "499:\tlearn: 0.2602372\ttotal: 2m 57s\tremaining: 0us\n",
      "\n",
      "Iteration 3\n",
      "High confidence pseudo-labels: 292744\n",
      "0:\tlearn: 0.6579862\ttotal: 476ms\tremaining: 3m 57s\n",
      "100:\tlearn: 0.2412777\ttotal: 46.5s\tremaining: 3m 3s\n",
      "200:\tlearn: 0.2381317\ttotal: 1m 30s\tremaining: 2m 13s\n",
      "300:\tlearn: 0.2365364\ttotal: 2m 15s\tremaining: 1m 29s\n",
      "400:\tlearn: 0.2356005\ttotal: 3m 1s\tremaining: 44.7s\n",
      "499:\tlearn: 0.2349129\ttotal: 3m 45s\tremaining: 0us\n",
      "\n",
      "Iteration 4\n",
      "High confidence pseudo-labels: 348455\n",
      "0:\tlearn: 0.6568887\ttotal: 496ms\tremaining: 4m 7s\n",
      "100:\tlearn: 0.2263774\ttotal: 49.8s\tremaining: 3m 16s\n",
      "200:\tlearn: 0.2235377\ttotal: 1m 39s\tremaining: 2m 27s\n",
      "300:\tlearn: 0.2223675\ttotal: 2m 28s\tremaining: 1m 38s\n",
      "400:\tlearn: 0.2214598\ttotal: 3m 18s\tremaining: 48.9s\n",
      "499:\tlearn: 0.2208474\ttotal: 4m 10s\tremaining: 0us\n",
      "\n",
      "Iteration 5\n",
      "High confidence pseudo-labels: 387696\n",
      "0:\tlearn: 0.6562147\ttotal: 509ms\tremaining: 4m 14s\n",
      "100:\tlearn: 0.2172418\ttotal: 52.3s\tremaining: 3m 26s\n",
      "200:\tlearn: 0.2148338\ttotal: 1m 43s\tremaining: 2m 33s\n",
      "300:\tlearn: 0.2137824\ttotal: 2m 34s\tremaining: 1m 42s\n",
      "400:\tlearn: 0.2130872\ttotal: 3m 27s\tremaining: 51.1s\n",
      "499:\tlearn: 0.2125133\ttotal: 4m 17s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "labeled_data = train[~train['Delay'].isnull()]\n",
    "unlabeled_data = train[train['Delay'].isnull()]\n",
    "\n",
    "X_labeled = labeled_data.drop(columns=['Delay'])\n",
    "y_labeled = labeled_data['Delay']\n",
    "X_unlabeled = unlabeled_data.drop(columns=['Delay'])\n",
    "\n",
    "# 범주형 데이터 타입 변환 (cat_features는 정수형 및 문자열 허용)\n",
    "for col in ['ID', 'Tail_Number', 'Carrier_ID(DOT)']:\n",
    "    X_labeled[col] = X_labeled[col].astype(str)\n",
    "    X_unlabeled[col] = X_unlabeled[col].astype(str)\n",
    "    test[col] = test[col].astype(str)\n",
    "\n",
    "le_delay = LabelEncoder()\n",
    "y_labeled = le_delay.fit_transform(y_labeled)\n",
    "\n",
    "# 클래스 간 불균형 문제 해결을 위해 가중치 부여\n",
    "class_counts = pd.Series(y_labeled).value_counts()\n",
    "balanced_weight = [1.0, 1.0]  # 균등 가중치\n",
    "\n",
    "cat_features = ['ID', 'Tail_Number', 'Carrier_ID(DOT)', 'Origin_Airport_ID', 'Destination_Airport_ID']\n",
    "teacher_model = CatBoostClassifier(\n",
    "    iterations=500, learning_rate=0.05, depth=6, cat_features=cat_features,\n",
    "    loss_function='MultiClass', class_weights=balanced_weight,\n",
    "    random_seed=42, verbose=100\n",
    ")\n",
    "student_model = CatBoostClassifier(\n",
    "    iterations=500, learning_rate=0.05, depth=6, cat_features=cat_features,\n",
    "    loss_function='MultiClass', class_weights=balanced_weight,\n",
    "    random_seed=42, verbose=100\n",
    ")\n",
    "\n",
    "# Teacher 모델 초기 학습\n",
    "teacher_model.fit(X_labeled, y_labeled)\n",
    "\n",
    "# Pseudo-labeling 및 Meta Pseudo Labeling 과정\n",
    "max_iter = 5\n",
    "confidence_threshold = 0.9  # 임계값 높임\n",
    "for iteration in range(max_iter):\n",
    "    print(f\"\\nIteration {iteration + 1}\")\n",
    "    \n",
    "    # Teacher가 pseudo-label 생성\n",
    "    pseudo_probs = teacher_model.predict_proba(X_unlabeled)\n",
    "    pseudo_labels = np.argmax(pseudo_probs, axis=1)\n",
    "    \n",
    "    # Confidence Threshold 적용\n",
    "    high_confidence_indices = np.max(pseudo_probs, axis=1) > confidence_threshold\n",
    "    print(f\"High confidence pseudo-labels: {high_confidence_indices.sum()}\")\n",
    "    if high_confidence_indices.sum() == 0:\n",
    "        print(\"No high-confidence samples in this iteration.\")\n",
    "        break\n",
    "    \n",
    "    # 레이블 있는 데이터 + high-confidence pseudo label 데이터를 결합하여 Student 학습\n",
    "    X_combined = pd.concat([X_labeled, X_unlabeled.iloc[high_confidence_indices]], axis=0)\n",
    "    y_combined = np.concatenate([y_labeled, pseudo_labels[high_confidence_indices]])\n",
    "    student_model.fit(X_combined, y_combined)\n",
    "    \n",
    "    # Teacher 업데이트\n",
    "    teacher_model = student_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 예측\n",
    "test_probs = student_model.predict_proba(test)\n",
    "test_probs = test_probs / test_probs.sum(axis=1, keepdims=True)\n",
    "\n",
    "# 제출 파일 생성\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test['ID'],\n",
    "    'Not_Delayed': test_probs[:, 0],\n",
    "    'Delayed': test_probs[:, 1]\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
